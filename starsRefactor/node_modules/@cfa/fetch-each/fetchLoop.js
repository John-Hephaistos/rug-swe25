import { fetchEach } from "./mod.js";
/** This function recursively goes into the queue as long as the resulting responses have more to do that wasn't already done */ export const fetchLoop = async (context)=>{
  let already = [];
  let urls = context.urls;
  let depth = 0;
  while(true){
    depth += 1;
    if (context.maxDepth && depth >= context.maxDepth) {
      break;
    }
    const requests = urls.map((url)=>({
        url: `${context.proxy}/${encodeURIComponent(url)}`,
        headers: context.headers
      }));
    const { basePath, apiKey } = context;
    const results = await fetchEach(requests, {
      basePath,
      apiKey
    });
    // we have now done these urls
    already = already.concat(urls);
    if (context.maxCount && already.length >= context.maxCount) {
      break;
    }
    // go again with all links we found that we haven't searched yet
    const searchableUrls = results.map((item)=>item.result ? context.getResultRequests(item.result).filter((url)=>!context.prefix || url.startsWith(context.prefix)) : []).flat().filter(Boolean);
    urls = Array.from(new Set(...searchableUrls.filter((url)=>!already.includes(url))));
    if (urls.length === 0) {
      break;
    }
  }
};
//# sourceMappingURL=fetchLoop.js.map